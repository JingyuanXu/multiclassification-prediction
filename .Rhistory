train$damage_grade[is.na(train$damage_grade)]='One'
is.na(train$damage_grade) ='One'
table(train$damage_grade)
train$damage_grade[is.na(train$damage_grade)]='One'
is.na(train$damage_grade)
train$damage_grade[is.na(train$damage_grade)='One'
train$damage_grade[is.na(train$damage_grade)]='One'
train$damage_grade[,is.na(train$damage_grade)]='One'
replace(train, is.na(train), "One")
str(train$damage_grade)
train=train[-41]
train=train[,-41]
dim(train)
summary(train)
# train=train[,-41]
str(train_label)
#
# y <- ... # factor of positive / negative cases
# predictions <- ... # factor of predictions
#
# precision <- posPredValue(predictions, y, positive="1")
# recall <- sensitivity(predictions, y, positive="1")
#
# F1 <- (2 * precision * recall) / (precision + recall)
(train_label$damage_grade==1)='One'
#
# y <- ... # factor of positive / negative cases
# predictions <- ... # factor of predictions
#
# precision <- posPredValue(predictions, y, positive="1")
# recall <- sensitivity(predictions, y, positive="1")
#
# F1 <- (2 * precision * recall) / (precision + recall)
train_label$damage_grade[train_label$damage_grade==1]='One'
str(trian_labe;)
str(trian_label)
train_label
train_label$damage_grade[train_label$damage_grade==1]='One'
train_label$damage_grade[train_label$damage_grade==2]='Two'
train_label$damage_grade[train_label$damage_grade==3]='Three'
str(train)
str(train_label)
train_label=as.factor(train_label)
train_label$damage_grade=as.factor(train_label$damage_grade)
str(train_label)
train_data = read.csv(file.choose(), header = T)
train_label =
read.csv(file.choose(), header = T)
test_data = read.csv(file.choose(), header =
T)
# str(train_data)
# str(train_label)
train_label$damage_grade[train_label$damage_grade==1]='One'
train_label$damage_grade[train_label$damage_grade==2]='Two'
train_label$damage_grade[train_label$damage_grade==3]='Three'
train_label$damage_grade=as.factor(train_label$damage_grade)
train=cbind(train_data,train_label)
summary(train)
dim(train)
train=train[,-41]
str(train$damage_grade)
dim(train)
str(train$damage_grade)
dim(train)
summary(train)
train=cbind(train_data,train_label)
summary(train)
train=train[,-40]
str(train$damage_grade)
###remove dulipate build_id
# train=train[,-40]
### 5 times 10 folds cc
set.seed(4321)
fitControl=trainControl(
method='cv',number=5,classProbs = T,returnResamp ='none',allowParallel = T,verboseIter=T,summaryFunction=multiClassSummary
)
### use gbm model to predict
fit <- train(damage_grade~., data=train, trControl=fitControl, method="gbm",metric='multiClassSummary'
)
mlog
### use gbm model to predict
fit <- train(damage_grade~., data=train, trControl=fitControl, method="gbm",metric='mlogloss'
)
print(fit)
set.seed(4321)
fitControl=trainControl(
method='cv',number=10,classProbs = T,returnResamp ='none',allowParallel = T,verboseIter=T,summaryFunction=multiClassSummary
)
### use gbm model to predict
fit <- train(damage_grade~., data=train, trControl=fitControl, method="gbm",metric='logLoss'
)
print(fit)
set.seed(4321)
fitControl=trainControl(
method='cv',number=10,classProbs = T,returnResamp ='none',allowParallel = T,verboseIter=T,summaryFunction=multiClassSummary
)
### use gbm model to predict
gbm_model <- train(damage_grade~., data=train, trControl=fitControl, method="gbm",metric='logLoss')
gbm_model <- train(damage_grade~., data=train, trControl=fitControl, method="gbm",metric='logLoss')
rf_model=train(damage_grade~.,data=train,trControl=fitControl,method='ranger',metric='logLoss')
print(gbm_model)
print(rf_model)
results <- resamples(list(GBM=gbm_model, Ranger=rf_model))
# summarize results
summary(results)
results = resamples(list(GBM=gbm_model, Ranger=rf_model))
results = resamples(list(GBM=gbm_model, Ranger=rf_model))
?resamples
## tmp <- createDataPartition(logBBB,
##                            p = .8,
##                            times = 100)
## rpartFit <- train(bbbDescr, logBBB,
##                   "rpart",
##                   tuneLength = 16,
##                   trControl = trainControl(
##                     method = "LGOCV", index = tmp))
## ctreeFit <- train(bbbDescr, logBBB,
##                   "ctree",
##                   trControl = trainControl(
##                     method = "LGOCV", index = tmp))
## earthFit <- train(bbbDescr, logBBB,
##                   "earth",
##                   tuneLength = 20,
##                   trControl = trainControl(
##                     method = "LGOCV", index = tmp))
## or load pre-calculated results using:
## load(url("http://caret.r-forge.r-project.org/exampleModels.RData"))
## resamps <- resamples(list(CART = rpartFit,
##                           CondInfTree = ctreeFit,
##                           MARS = earthFit))
## resamps
## summary(resamps)
data(BloodBrain)
set.seed(1)
tmp <- createDataPartition(logBBB,
p = .8,
times = 100)
rpartFit <- train(bbbDescr, logBBB,
"rpart",
tuneLength = 16,
trControl = trainControl(
method = "LGOCV", index = tmp))
ctreeFit <- train(bbbDescr, logBBB,
"ctree",
trControl = trainControl(
method = "LGOCV", index = tmp))
earthFit <- train(bbbDescr, logBBB,
"earth",
tuneLength = 20,
trControl = trainControl(
method = "LGOCV", index = tmp))
summary(resamps)
resamps
resamps <- resamples(list(CART = rpartFit,
CondInfTree = ctreeFit,
MARS = earthFit))
resamps
summary(resamps)
summary(resamps)
resamps
results = resamples(list(GBM=gbm_model, Ranger=rf_model))
fitControl=trainControl(
method='cv',number=10,classProbs = T,#returnResamp ='none',
allowParallel = T,verboseIter=T,summaryFunction=multiClassSummary
)
modelLookup("gbm")
modelLookup("ranger")
1:10
ranger_grid=expand.grid(.mtry=c(4,5,6,7,8),.splitrule=c('gini','extratrees'),.min.node.size=c(1:10))
(1:100,10)
(1:100)
c(1:100,seq=5)
gbm_grid=expand.grid(.n.trees=c(from=1,to=200,by=5),.interaction.depth=c(from=1,to=20,by=2),.shrinkage=c(from=0.05,to=1,by=0.05),.n.minobsinnode=c(from=1,to=20,by=1))
ranger_grid=expand.grid(.mtry=c(4:8),.splitrule=c('gini','extratrees'),.min.node.size=c(1:10))
c(1,20,2)
c(from=1,to=20,by=2)
# use gbm  and ranger model to predict
## define the grid search for gbm and ranger
gbm_grid=expand.grid(.n.trees=seq(from=1,to=200,by=5),.interaction.depth=seq(from=1,to=20,by=2),.shrinkage=seq(from=0.05,to=1,by=0.05),.n.minobsinnode=seq(from=1,to=20,by=1))
gbm_grid
#                     trControl = trainControl(
#                       method = "LGOCV", index = tmp))
#
#
#   resamps <- resamples(list(CART = rpartFit,
#                             CondInfTree = ctreeFit,
#                             MARS = earthFit))
#
#   resamps
#   summary(resamps)
dotplot(resamps)
set.seed(4321)
fitControl=trainControl(
method='cv',number=10,classProbs = T,#returnResamp ='none',
allowParallel = T,verboseIter=T,summaryFunction=multiClassSummary
)
gbm_grid=expand.grid(.n.trees=seq(from=1,to=200,by=5),.interaction.depth=seq(from=1,to=20,by=2),.shrinkage=seq(from=0.05,to=1,by=0.05),.n.minobsinnode=seq(from=1,to=20,by=1))
ranger_grid=expand.grid(.mtry=c(4:8),.splitrule=c('gini','extratrees'),.min.node.size=c(1:10))
gbm_model = train(damage_grade~., data=train, trControl=fitControl,tuneGrid=gbm_grid, method="gbm",metric='logLoss')
library(caretEnsemble)
install.packages("caretEnsemble")
model_list_big = caretList(
damage_grade~.,
data=train,
trControl=fitControl,
metric="logLoss",
methodList=c("ranger", "gbm"),
tuneList=list(
rf1=caretModelSpec(method="ranger", tuneGrid=data.frame(.mtry=c(4:8),
.splitrule=c('gini','extratrees'),
.min.node.size=c(1:10))),
gbm2=caretModelSpec(method="gbm", tuneGrid=data.frame(.n.trees=seq(from=10,to=200,by=10),
.interaction.depth=seq(from=1,to=10,by=1),
.shrinkage=seq(from=0.1,to=1,by=0.1),
.n.minobsinnode=seq(from=1,to=20,by=1)
)))
)
library(caretEnsemble)
model_list_big = caretList(
damage_grade~.,
data=train,
trControl=fitControl,
metric="logLoss",
methodList=c("ranger", "gbm"),
tuneList=list(
rf1=caretModelSpec(method="ranger", tuneGrid=data.frame(.mtry=c(4:8),
.splitrule=c('gini','extratrees'),
.min.node.size=c(1:10))),
gbm2=caretModelSpec(method="gbm", tuneGrid=data.frame(.n.trees=seq(from=10,to=200,by=10),
.interaction.depth=seq(from=1,to=10,by=1),
.shrinkage=seq(from=0.1,to=1,by=0.1),
.n.minobsinnode=seq(from=1,to=20,by=1)
)))
)
model_list_big = caretList(
damage_grade~.,
data=train,
trControl=fitControl,
metric="logLoss",
methodList=c("ranger", "gbm"),
tuneList=list(
rf1=caretModelSpec(method="ranger"
#,  tuneGrid=data.frame(.mtry=c(4:8),
# .splitrule=c('gini','extratrees'),
# .min.node.size=c(1:10))
),
gbm2=caretModelSpec(method="gbm"
# ,tuneGrid=data.frame(.n.trees=seq(from=10,to=200,by=10),
#                                   .interaction.depth=seq(from=1,to=10,by=1),
#                                   .shrinkage=seq(from=0.1,to=1,by=0.1),
#                                   .n.minobsinnode=seq(from=1,to=20,by=1)
#                                   )
)
)
)
gbm_model
rf_gbm_ensemble=caretEnsemble(
model_list_big,
metric='logLoss',
trControl=trainControl(
number=5,
allowParallel = T,
verboseIter=T,
summaryFunction=multiClassSummary
)
)
rf_gbm_ensemble=caretEnsemble(
model_list_big,
metric='logLoss',
trControl=trainControl(
number=5,
allowParallel = T,
verboseIter=T,
summaryFunction=multiClassSummary
)
)
rf_gbm_ensemble=caretEnsemble(
model_list_big,
metric='logLoss',
trControl=trainControl(
number=5,
allowParallel = T,
verboseIter=T
)
)
##ensemble
model_list_big
rf_gbm_ensemble=caretEnsemble(
model_list_big,
metric='logLoss',
trControl=trainControl(
number=5,
allowParallel = T,
verboseIter=T
)
)
model_list_big = caretList(
damage_grade~.,
data=train,
trControl=fitControl,
metric="logLoss",
methodList=c("ranger", "gbm")
#, tuneList=list(
#   rf1=caretModelSpec(method="ranger"
#                     ,  tuneGrid=data.frame(.mtry=c(4:8),
#                     .splitrule=c('gini','extratrees'),
#                     .min.node.size=c(1:10))
#                      ),
#   gbm2=caretModelSpec(method="gbm"
#                       ,tuneGrid=data.frame(.n.trees=seq(from=10,to=200,by=10),
#                                                         .interaction.depth=seq(from=1,to=10,by=1),
#                                                         .shrinkage=seq(from=0.1,to=1,by=0.1),
#                                                         .n.minobsinnode=seq(from=1,to=20,by=1))))
)
##ensemble
model_list_big
rf_gbm_ensemble=caretEnsemble(
model_list_big,
metric='logLoss',
trControl=trainControl(
number=5,
allowParallel = T,
verboseIter=T
)
)
?caretEnsemble
rf_gbm_ensemble=caretEnsemble(
type="multiclassification",
model_list_big,
metric='logLoss',
trControl=trainControl(
number=5,
allowParallel = T,
verboseIter=T
)
)
rf_gbm_ensemble=caretEnsemble(
type="multiclass",
model_list_big,
metric='logLoss',
trControl=trainControl(
number=5,
allowParallel = T,
verboseIter=T
)
)
# use gbm  and ranger model to predict
## define the grid search for gbm and ranger
# gbm_grid=expand.grid(.n.trees=seq(from=10,to=200,by=10),.interaction.depth=seq(from=1,to=10,by=1),.shrinkage=seq(from=0.1,to=1,by=0.1),.n.minobsinnode=seq(from=1,to=20,by=1))
# ranger_grid=expand.grid(.mtry=c(4:8),.splitrule=c('gini','extratrees'),.min.node.size=c(1:10))
# gbm_model = train(damage_grade~., data=train, trControl=fitControl,tuneGrid=gbm_grid, method="gbm",metric='logLoss')
# rf_model=train(damage_grade~.,data=train,trControl=fitControl,tuneGrid=ranger_grid,method='ranger',metric='logLoss')
# print(gbm_model)
# print(rf_model)
pre=predict(gbm_model,test)
# use gbm  and ranger model to predict
## define the grid search for gbm and ranger
# gbm_grid=expand.grid(.n.trees=seq(from=10,to=200,by=10),.interaction.depth=seq(from=1,to=10,by=1),.shrinkage=seq(from=0.1,to=1,by=0.1),.n.minobsinnode=seq(from=1,to=20,by=1))
# ranger_grid=expand.grid(.mtry=c(4:8),.splitrule=c('gini','extratrees'),.min.node.size=c(1:10))
# gbm_model = train(damage_grade~., data=train, trControl=fitControl,tuneGrid=gbm_grid, method="gbm",metric='logLoss')
# rf_model=train(damage_grade~.,data=train,trControl=fitControl,tuneGrid=ranger_grid,method='ranger',metric='logLoss')
# print(gbm_model)
# print(rf_model)
pre=predict(gbm_model,test_data)
pre
# use gbm  and ranger model to predict
## define the grid search for gbm and ranger
# gbm_grid=expand.grid(.n.trees=seq(from=10,to=200,by=10),.interaction.depth=seq(from=1,to=10,by=1),.shrinkage=seq(from=0.1,to=1,by=0.1),.n.minobsinnode=seq(from=1,to=20,by=1))
# ranger_grid=expand.grid(.mtry=c(4:8),.splitrule=c('gini','extratrees'),.min.node.size=c(1:10))
# gbm_model = train(damage_grade~., data=train, trControl=fitControl,tuneGrid=gbm_grid, method="gbm",metric='logLoss')
# rf_model=train(damage_grade~.,data=train,trControl=fitControl,tuneGrid=ranger_grid,method='ranger',metric='logLoss')
# print(gbm_model)
# print(rf_model)
pre_gbm=predict(gbm_model,test_data)
table(pre_gbm)
pre_ranger=predict(rf_model,test_data)
table(pre_ranger)
dim(test_data)
result_gbm=cbind(test_data[,1],pre_gbm)
result_gbm
str(result_gbm)
head(test_data)
str(result_gbm)
colnames(result_gbm)=c('buildong_id','damage_grade')
str(result_gbm)
result_gbm
write.csv(result_gbm,'gbm1.csv',seq="",col.names = T,row.names = F)
write.csv(result_gbm,'gbm1.csv',sep="",secol.names = T,row.names = F)
write.csv(result_gbm,'gbm1.csv',sep="",col.names = T,row.names = F)
result_ranger=cbind(test_data[,1],pre_ranger)
colnames(result_ranger)=c('buildong_id','damage_grade')
str(result_ranger)
write.csv(result_ranger,'ranger1.csv',sep="",col.names = T,row.names = F)
library(xgboost)
summary(train)
dim(train)
train_boost=train[,1:39]
dim(train_boost)
train_boost_target=train$damage_grade
train_matrix=model.matrix(~.-1,data=train_boost)
train_matrix
train_matrix
dum(train_matrix)
dim(train_matrix)
xgb_grid <- expand.grid(
nrounds=c(350),
max_depth = c(4, 6),
eta = c(0.05, 0.1),
gamma = c(0.01),
colsample_bytree = c(0.75),
subsample = c(0.50),
min_child_weight = c(0))
train_matrix
xgb_grid <- expand.grid(
nrounds=c(350),
max_depth = c(4, 6),
eta = c(0.05, 0.1),
gamma = c(0.01),
colsample_bytree = c(0.75),
subsample = c(0.50),
min_child_weight = c(0))
xgb_model=train(x=train_matrix,
y=train_boost_target,
trControl=fitControl,
tuneGrid=xgb_grid,
method='xgbTree',
metric='logLoss')
library(caret)
library(caretEnsemble)
library(xgboost)
xgb_model=train(x=train_matrix,
y=train_boost_target,
trControl=fitControl,
tuneGrid=xgb_grid,
method='xgbTree',
metric='logLoss')
train_boost_target
train$damage_grade
train
train_label
summary(train)
train_label$damage_grade[train_label$damage_grade==1]='One'
train_label$damage_grade[train_label$damage_grade==2]='Two'
train_label$damage_grade[train_label$damage_grade==3]='Three'
train_label$damage_grade=as.factor(train_label$damage_grade)
train=cbind(train_data,train_label)
summary(train)
dim(train)
#remove dulipate build_id
train=train[,-40]
###for xgboost only
train_boost=train[,1:39]
train_boost_target=train$damage_grade
train_matrix=model.matrix(~.-1,data=train_boost)
train_label
train_boost_target
xgb_model=train(x=train_matrix,
y=train_boost_target,
trControl=fitControl,
tuneGrid=xgb_grid,
method='xgbTree',
metric='logLoss')
getModelInfo(xgboost)
getModelInfo('xgboost')
modelLookup(xgboost)
modelLookup('xgboost')
modelLookup('ranger')
modelLookup('xgboost')
modelLookup('xgbTree')
xgb_grid <- expand.grid(
nrounds=seq(50,500,50),
max_depth = seq(2,10,2),
eta = seq(0.0, 0.5,0.1),
gamma = seq(0.,1,0.1),
colsample_bytree = seq(0.,0.8,0.2),
subsample = seq(0.,0.8,0.2),
min_child_weight = seq(0,1,0.25)
)
xgb_model=train(x=train_matrix,
y=train_boost_target,
trControl=fitControl,
tuneGrid=xgb_grid,
method='xgbTree',
metric='logLoss')
xgb_model=train(x=train_matrix,
y=train_boost_target,
trControl=fitControl,
#tuneGrid=xgb_grid,
method='xgbTree',
metric='logLoss')
####predict with the model
pre_gbm=predict(gbm_model,test_data)
test_martrix=model.matrix(~.-1, data=test_data)
pre_xgb=predict(xgb_model,test_matrix)
pre_xgb=predict(xgb_model,test_martrix)
pre_xgb
result_xgb=cbind(test_data[,1],pre_xgb)
result_xgb
colnames(result_xgb)=c('buildong_id','damage_grade')
write.csv(result_xgb,'xgb1.csv',sep="",col.names = T,row.names = F)
write.csv(result_xgb,'xgb1.csv',sep="",col.names = T,row.names = F,quote=F)
table(result_xgb)
summary(result_xgb)
table(pre_xgb)
confusionMatrix(train_boost)
varImp(pre_xgb)
prcomp(train)
prcomp(train_matrix)
test= prcomp(train,scale=T)
prcomp(USArrests,scale=T)
USArrests
varImp(xgb_model)
